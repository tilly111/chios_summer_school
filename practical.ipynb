{
 "cells": [
  {
   "cell_type": "markdown",
   "source": [
    "# Practical: Automated Feedback from Physiological Data for Time Perception\n",
    "Welcome to the practical on automated feedback from physiological data for time perception.\n",
    "In this practical you will learn about the following 4 topics:\n",
    "1. Data cleaning: Removing noise and artifacts from the raw data.\n",
    "2. Feature extraction: Identifying relevant features from the cleaned data that are indicative of time perception.\n",
    "3. Classification: Using machine learning algorithms to classify data based on extracted features.\n",
    "4. Additional steps: Exploring advanced techniques such as feature selection methods, feature importance measurements, and automated machine learning (AutoML).\n",
    "\n",
    "We will use the same data as Aust et al. 2024 (https://arxiv.org/abs/2404.15213). For simplicity, we will only use electrodermal activity (EDA) data.\n",
    "So without further ado, let's get started!\n",
    "First you will import required libraries."
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 75,
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "!pip install neurokit2\n",
    "import neurokit2 as nk\n",
    "\n",
    "from sklearn.tree import DecisionTreeClassifier\n",
    "from sklearn.svm import SVC\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.metrics import accuracy_score, f1_score, roc_auc_score\n",
    "\n",
    "!pip install shap\n",
    "import shap\n",
    "from sklearn.feature_selection import RFECV, SequentialFeatureSelector\n",
    "\n",
    "!pip install naiveautoml\n",
    "import naiveautoml\n",
    "import logging\n",
    "\n",
    "# connect your drive\n",
    "from google.colab import drive\n",
    "drive.mount('/content/drive')"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "# 1. Data Cleaning\n",
    "Great! Now we have all required libraries imported. Next, we will load the data."
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "# load the raw EDA data\n",
    "raw_eda = ...\n",
    "\n",
    "# display the overall shape and the column names of the data\n",
    "...\n",
    "\n",
    "# display the first few rows of the data\n",
    "..."
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "is_executing": true
    }
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "Okay, the data consists of a `LocalTimestamp` and `EA` that is the raw EDA data. Next, we will plot the raw EDA data."
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "# plot the raw EDA data\n",
    "plt.figure(figsize=(15, 5))\n",
    "...\n",
    "plt.xlabel('Time')\n",
    "plt.ylabel('EDA')\n",
    "plt.title('Raw EDA data')"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "is_executing": true
    }
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "You may have noticed that the time axis does not tell you anything. To make it more informative, we will convert the `LocalTimestamp` to a more readable format. We can do this by subtracting the first timestamp from all timestamps such that each experiment starts at 0."
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "# subtract the first time stamp from all other time stamps an plot the data again\n",
    "raw_eda['LocalTimestamp'] = ...\n",
    "\n",
    "# plot the raw EDA data\n",
    "plt.figure(figsize=(15, 5))\n",
    "...\n",
    "plt.xlabel('Time')\n",
    "plt.ylabel('EDA')\n",
    "plt.title('Raw EDA data')"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "is_executing": true
    }
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "Now the time make sense, it seems that the experiment lasted for about 180 seconds or 3 minutes. Next, we will clean the data to remove noise and artifacts. Therefore, we use the NeuroKit library we imported earlier. Before we can clean the data we need to know the sampling rate of our data because this information is a parameter we need to hand over to the cleaning method."
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "# calculate the sampling rate of the eda data in Hz\n",
    "sampling_rate = ...\n",
    "sampling_rate_int = ...\n",
    "\n",
    "print(f\"Sampling rate: {sampling_rate} Hz\")\n",
    "print(f\"Rounded sampling rate: {sampling_rate_int} Hz\")\n",
    "\n",
    "# clean the data using the NeuroKit library\n",
    "#  You can check out the documentation here: https://neuropsychology.github.io/NeuroKit/functions/eda.html\n",
    "#  You can use report=\"subject_1_report.html\" to print a visual overview of the cleaning process\n",
    "cleaned_eda_signals, info = ..."
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%% \n",
     "is_executing": true
    }
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "The `cleaned_eda_signals` contain the cleaned EDA data. `info` contains information of each SCR peak and sampling frequency.\n",
    "Now, we can plot the individual EDA components, needed for calculating the features."
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "# plot the individual EDA components\n",
    "plt.figure(figsize=(15, 5))\n",
    "...\n",
    "plt.legend()"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "is_executing": true
    }
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "## 2. Feature Extraction\n",
    "Next, we can use the cleaned EDA data to extract features. We will use the following features: SCR peaks, SCR peak amplitude mean, EDA tonic standard deviation, EDA sympathetic, EDA sympathetic N, EDA autocorrelation. The NeuroKit library provides a function to extract these features."
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 81,
   "outputs": [],
   "source": [
    "# extract features from the cleaned EDA data\n",
    "#  method can be \"interval-related\" or \"event-related\" (event-related is for sequences under 10 seconds) and we are using an interval and not events\n",
    "eda_features = ..."
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "Great, now we have extracted the EDA features. Now we need to get the subjective time perception of the participants.\n",
    "We start by loading the questionnaire answers of all participants."
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "# load the questionnaire answers\n",
    "questionnaire = ...\n",
    "\n",
    "# display the first few rows of the data\n",
    "..."
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "is_executing": true
    }
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "The important columns are `ParticipantID` and `Session` to assign the corresponding answer to the setting and participant. Further, the column `PassageOfTimeSlowFast` provides us with the answer of slow or fast subjective time perception.\n",
    "So now we can extract the answer for the first participant and first session.\n",
    "(The mapping is 1: very slow, 2: slow, 3: normal, 4: fast, 5: very fast)"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "# select the subjective time perception of participant 1 in session 1\n",
    "subjective_time_perception_label = ...\n",
    "\n",
    "# print the subjective time perception\n",
    "..."
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "is_executing": true
    }
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "Now you learned how you can get the features and the appropriate labels. In the next step you will automate the process for all participants and sessions."
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 84,
   "outputs": [],
   "source": [
    "# define the participants\n",
    "participants = [1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 11, 12]\n",
    "# define the sessions\n",
    "sessions = [1, 2, 3, 4]\n",
    "\n",
    "# final Pandas dataframe that holds all data\n",
    "all_data = pd.DataFrame(columns=[\"participant\", \"session\", \"SCR_Peaks_N\",\n",
    "                    \"SCR_Peaks_Amplitude_Mean\",\n",
    "                    \"EDA_Tonic_SD\",\n",
    "                    \"EDA_Sympathetic\",\n",
    "                    \"EDA_SympatheticN\",\n",
    "                    \"EDA_Autocorrelation\", \"subjective_time_perception\"])\n",
    "counter = 0\n",
    "\n",
    "# iterate over all participants\n",
    "for p in participants:\n",
    "    # iterate over all sessions\n",
    "    for s in sessions:\n",
    "        # load the raw EDA data\n",
    "        ...\n",
    "        # subtract the first time stamp from all other time stamps\n",
    "        ...\n",
    "        # calculate the sampling rate of the eda data in Hz\n",
    "        ...\n",
    "\n",
    "        # clean the data using the NeuroKit library\n",
    "        cleaned_eda_signals, info = ...\n",
    "\n",
    "        # extract features from the cleaned EDA data\n",
    "        eda_features = ...\n",
    "\n",
    "        # select the subjective time perception of the participant in the session\n",
    "        subjective_time_perception_label = ...\n",
    "\n",
    "        # append the data to the final dataframe\n",
    "        all_data.loc[counter] = [p, s, float(eda_features[\"SCR_Peaks_N\"].iloc[0]), float(eda_features[\"SCR_Peaks_Amplitude_Mean\"].iloc[0]), float(eda_features[\"EDA_Tonic_SD\"].iloc[0]), float(eda_features[\"EDA_Sympathetic\"].iloc[0]), float(eda_features[\"EDA_SympatheticN\"].iloc[0]), float(eda_features[\"EDA_Autocorrelation\"].iloc[0]), subjective_time_perception_label]\n",
    "        counter += 1"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "Great! Now you have all the data in one place. Next, we will use machine learning to classify the data based on the extracted features.\n",
    "Therefore, we first split the data into training and test data. We will use 80% of the data for training and 20% for testing."
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "# split the data into training and testing data (80% training, 20% testing)\n",
    "#  random_state is set to 42 to ensure reproducibility\n",
    "x_train, x_test, y_train, y_test = ...\n",
    "\n",
    "print(f\"X train shape: {x_train.shape}, X test shape: {x_test.shape}, y train shape: {y_train.shape}, y test shape: {y_test.shape}\")"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "is_executing": true
    }
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "## 3. Classification\n",
    "Now we can use the training data to train our classifier and evaluate it on the test data."
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "# create classifier\n",
    "#  see: https://scikit-learn.org/stable/modules/generated/sklearn.tree.DecisionTreeClassifier.html for more information and hyperparameter selection\n",
    "dtc = ...\n",
    "\n",
    "# train the classifier\n",
    "...\n",
    "\n",
    "# evaluate the classifier\n",
    "#  predict the labels of the test data\n",
    "y_pred = ...\n",
    "#  predict the probabilities of the test data\n",
    "y_pred_proba = ...\n",
    "\n",
    "# calculate the accuracy of the classifier\n",
    "print(f\"Accuracy: {...}\")\n",
    "# calculate the F1 score of the classifier\n",
    "print(f\"F1 score: {...}\")\n",
    "# calculate the ROC AUC score of the classifier\n",
    "print(f\"ROC AUC score: {...}\")"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "is_executing": true
    }
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "## 4. Additional steps\n",
    "Great! You have successfully trained and evaluated a classifier to predict subjective time perception based on EDA features.\n",
    "However, the results are not so satisfying yet. Therefore, we will explore additional steps to improve the classification performance.\n",
    "Let's start with simplifying the problem by reducing the number of classes."
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "# reduce the number of classes to slow and fast\n",
    "all_data['subjective_time_perception_reduced'] = ...\n",
    "\n",
    "# let's see the distribution of the classes before and after\n",
    "plt.figure(figsize=(10, 5))\n",
    "plt.subplot(1, 2, 1)\n",
    "...\n",
    "plt.title('Subjective time perception distribution')\n",
    "plt.xlabel('Subjective time perception')\n",
    "plt.ylabel('Frequency')\n",
    "plt.subplot(1, 2, 2)\n",
    "...\n",
    "plt.title('Reduced subjective time perception distribution')\n",
    "plt.xlabel('Subjective time perception')\n",
    "plt.ylabel('Frequency')"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "is_executing": true
    }
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "This simplified the problem. Let's train and evaluate the classifier again. We will try a different classifier this time: Random Forest (ensemble of decision trees)."
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "# use the reduced label\n",
    "x_train, x_test, y_train, y_test = ...\n",
    "\n",
    "print(f\"X train shape: {x_train.shape}, X test shape: {x_test.shape}, y train shape: {y_train.shape}, y test shape: {y_test.shape}\")\n",
    "\n",
    "\n",
    "rfc = ...\n",
    "\n",
    "# train the classifier\n",
    "...\n",
    "\n",
    "# evaluate the classifier\n",
    "#  predict the labels of the test data\n",
    "...\n",
    "\n",
    "# calculate the accuracy of the classifier\n",
    "print(f\"Accuracy: {...}\")\n",
    "# calculate the F1 score of the classifier\n",
    "print(f\"F1 score: {...}\")\n",
    "# calculate the ROC AUC score of the classifier\n",
    "print(f\"ROC AUC score: {...)}\")"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "is_executing": true
    }
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "Great! The classification performance improved. Next, we will explore feature importance to identify the most relevant features.\n",
    "Therefore, we will use shape-based feature importance."
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "# create the explainer\n",
    "explainer = ...\n",
    "# calculate the shap values based on the test data\n",
    "shap_value = ...\n",
    "# returns probability for class 0 and 1, but we only need one bc p = 1 - p\n",
    "shap_value.values = shap_value.values[:, :, 1]\n",
    "shap_value.base_values = shap_value.base_values[:, 1]\n",
    "\n",
    "# plot the feature importance\n",
    "plt.figure()\n",
    "shap.plots.bar(shap_value, max_display=..., show=True)"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "is_executing": true
    }
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "Seeing that some features are more important than others, we can try to remove the less important features and retrain the classifier."
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "# create a sequential feature selector\n",
    "selector = ...\n",
    "# fit the selector based on the training data\n",
    "x_train = ...\n",
    "# transform the test data accordingly\n",
    "x_test = ...\n",
    "\n",
    "# store results\n",
    "result_df = pd.DataFrame(zip([\"SCR_Peaks_N\", \"SCR_Peaks_Amplitude_Mean\", \"EDA_Tonic_SD\", \"EDA_Sympathetic\", \"EDA_SympatheticN\", \"EDA_Autocorrelation\"], selector.get_support()))\n",
    "result_df.columns = [\"features\", \"used\"]\n",
    "\n",
    "# print the results\n",
    "print(result_df)\n",
    "\n",
    "# train the classifier\n",
    "...\n",
    "\n",
    "# evaluate the classifier\n",
    "#  predict the labels of the test data\n",
    "...\n",
    "\n",
    "# calculate the accuracy of the classifier\n",
    "print(f\"Accuracy: {...}\")\n",
    "# calculate the F1 score of the classifier\n",
    "print(f\"F1 score: {...}\")\n",
    "# calculate the ROC AUC score of the classifier\n",
    "print(f\"ROC AUC score: {...}\")"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "is_executing": true
    }
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "Finally, we can have a look at automated model selection, which can be helpful to find the correct hyperparameters for the classifier."
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "# do logging\n",
    "logger = logging.getLogger('naiveautoml')\n",
    "logger.setLevel(logging.INFO)\n",
    "ch = logging.StreamHandler()\n",
    "ch.setLevel(logging.INFO)\n",
    "formatter = logging.Formatter('%(asctime)s - %(name)s - %(levelname)s - %(message)s')\n",
    "ch.setFormatter(formatter)\n",
    "logger.addHandler(ch)\n",
    "\n",
    "# create the NaiveAutoML object\n",
    "naml = ...\n",
    "\n",
    "# fit the NaiveAutoML object\n",
    "...\n",
    "\n",
    "# print the best model\n",
    "print(\"---------------------------------\")\n",
    "print(naml.chosen_model)\n",
    "print(\"---------------------------------\")"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "is_executing": true
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "# Testing the findings from the AutoML\n",
    "svc = ...\n",
    "\n",
    "# fit classifier\n",
    "...\n",
    "\n",
    "# predict classifier labels\n",
    "y_pred = ...\n",
    "\n",
    "# calculate the accuracy of the classifier\n",
    "print(f\"Accuracy: {...}\")"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "is_executing": true
    }
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "### Conclusion\n",
    "Now you have learned the basics of processing and classifying physiological data for time perception. You have learned how to clean the data, extract features, classify the data, and explore additional steps to improve the classification performance.\n",
    "\n",
    "It is time to explore the data on your own. You can try different classifiers, feature selection methods, and hyperparameter optimization techniques to improve the classification performance further. You can also try different features or even combine features from different physiological data sources to improve the classification performance.\n",
    "\n",
    "You can also play around with the sequences provided by the `timestamps.csv`."
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "# TODO play around!"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "is_executing": true
    }
   }
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
